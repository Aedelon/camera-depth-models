{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "header"
   },
   "source": [
    "# üé® RGBD-Depth: Real-time Depth Refinement ‚Äî Quickstart\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Aedelon/camera-depth-models/blob/main/quickstart_colab.ipynb)\n",
    "[![PyPI](https://img.shields.io/pypi/v/rgbd-depth.svg)](https://pypi.org/project/rgbd-depth/)\n",
    "[![GitHub](https://img.shields.io/github/stars/Aedelon/rgbd-depth.svg?style=social)](https://github.com/Aedelon/camera-depth-models)\n",
    "\n",
    "Transform noisy depth camera data into clean, simulation-quality depth maps using Vision Transformers.\n",
    "\n",
    "**This notebook:**\n",
    "- ‚úÖ Installs `rgbd-depth` from PyPI\n",
    "- ‚úÖ Downloads example RGB-D data\n",
    "- ‚úÖ Runs depth refinement in ~2s on Colab GPU\n",
    "- ‚úÖ Visualizes before/after comparison\n",
    "\n",
    "**Use cases:** Robotics, AR/VR, 3D reconstruction, sim-to-real transfer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "installation"
   },
   "source": [
    "## üì¶ Installation\n",
    "\n",
    "Install the package from PyPI (takes ~30s):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install"
   },
   "outputs": [],
   "source": [
    "!pip install -q rgbd-depth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "download_data"
   },
   "source": [
    "## üñºÔ∏è Download Example Data\n",
    "\n",
    "We'll use real RGB-D data from an Intel RealSense D435 camera:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "download"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "\n",
    "# Create example_data directory\n",
    "os.makedirs(\"example_data\", exist_ok=True)\n",
    "\n",
    "# Base URL for example data\n",
    "base_url = \"https://raw.githubusercontent.com/Aedelon/camera-depth-models/main/example_data/\"\n",
    "\n",
    "# Download RGB and depth images\n",
    "files = [\"color_12.png\", \"depth_12.png\"]\n",
    "for filename in files:\n",
    "    url = base_url + filename\n",
    "    filepath = os.path.join(\"example_data\", filename)\n",
    "    print(f\"Downloading {filename}...\")\n",
    "    urllib.request.urlretrieve(url, filepath)\n",
    "\n",
    "print(\"‚úÖ Example data downloaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "inference"
   },
   "source": [
    "## üöÄ Run Depth Refinement\n",
    "\n",
    "Load the model and refine the depth map:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "run_inference"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from rgbddepth import RGBDDepth\n",
    "\n",
    "# Initialize model (downloads checkpoint on first run ~300MB)\n",
    "print(\"Loading model...\")\n",
    "model = RGBDDepth(\n",
    "    camera_type=\"d435\",  # Intel RealSense D435\n",
    "    device=\"auto\",       # Auto-detect GPU/CPU\n",
    "    use_xformers=True    # Enable optimizations if available\n",
    ")\n",
    "\n",
    "# Load RGB and depth images\n",
    "rgb = cv2.imread(\"example_data/color_12.png\")\n",
    "rgb = cv2.cvtColor(rgb, cv2.COLOR_BGR2RGB)  # BGR ‚Üí RGB\n",
    "\n",
    "depth_raw = cv2.imread(\"example_data/depth_12.png\", cv2.IMREAD_UNCHANGED)\n",
    "depth_raw = depth_raw.astype(np.float32) / 1000.0  # mm ‚Üí meters\n",
    "\n",
    "print(f\"Input shape: RGB={rgb.shape}, Depth={depth_raw.shape}\")\n",
    "\n",
    "# Run inference\n",
    "print(\"Running depth refinement...\")\n",
    "depth_refined = model(rgb, depth_raw)\n",
    "\n",
    "print(f\"‚úÖ Refinement complete! Output shape: {depth_refined.shape}\")\n",
    "print(f\"   Depth range: {depth_refined.min():.3f}m - {depth_refined.max():.3f}m\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "visualization"
   },
   "source": [
    "## üìä Visualize Results\n",
    "\n",
    "Compare raw vs refined depth:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "visualize"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create visualization\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "# RGB input\n",
    "axes[0].imshow(rgb)\n",
    "axes[0].set_title(\"RGB Input\", fontsize=14, fontweight=\"bold\")\n",
    "axes[0].axis(\"off\")\n",
    "\n",
    "# Raw depth (noisy)\n",
    "im1 = axes[1].imshow(depth_raw, cmap=\"turbo\", vmin=0, vmax=3)\n",
    "axes[1].set_title(\"Raw Depth (Noisy)\", fontsize=14, fontweight=\"bold\")\n",
    "axes[1].axis(\"off\")\n",
    "plt.colorbar(im1, ax=axes[1], fraction=0.046, pad=0.04, label=\"Depth (m)\")\n",
    "\n",
    "# Refined depth (clean)\n",
    "im2 = axes[2].imshow(depth_refined, cmap=\"turbo\", vmin=0, vmax=3)\n",
    "axes[2].set_title(\"Refined Depth ‚ú®\", fontsize=14, fontweight=\"bold\", color=\"green\")\n",
    "axes[2].axis(\"off\")\n",
    "plt.colorbar(im2, ax=axes[2], fraction=0.046, pad=0.04, label=\"Depth (m)\")\n",
    "\n",
    "plt.suptitle(\"RGBD-Depth: Real-time Depth Refinement\", fontsize=16, fontweight=\"bold\", y=0.98)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print quality metrics\n",
    "noise_reduction = np.std(depth_raw[depth_raw > 0]) - np.std(depth_refined[depth_refined > 0])\n",
    "print(f\"\\nüìâ Noise reduction: {noise_reduction:.4f}m (lower is cleaner)\")\n",
    "print(f\"üìä Valid pixels: Raw={np.sum(depth_raw > 0):,} | Refined={np.sum(depth_refined > 0):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "next_steps"
   },
   "source": [
    "## üéØ Next Steps\n",
    "\n",
    "**Try different cameras:**\n",
    "```python\n",
    "model = RGBDDepth(camera_type=\"d405\")  # RealSense D405\n",
    "model = RGBDDepth(camera_type=\"l515\")  # RealSense L515\n",
    "model = RGBDDepth(camera_type=\"zed2i\") # ZED 2i\n",
    "model = RGBDDepth(camera_type=\"kinect_azure\") # Azure Kinect\n",
    "```\n",
    "\n",
    "**Optimize for speed:**\n",
    "```python\n",
    "# Enable mixed precision (2√ó faster on GPU)\n",
    "model = RGBDDepth(camera_type=\"d435\", precision=\"fp16\")\n",
    "```\n",
    "\n",
    "**Use your own data:**\n",
    "```python\n",
    "# Load your RGB-D pair\n",
    "rgb = cv2.imread(\"your_rgb.png\")\n",
    "rgb = cv2.cvtColor(rgb, cv2.COLOR_BGR2RGB)\n",
    "depth = cv2.imread(\"your_depth.png\", cv2.IMREAD_UNCHANGED).astype(np.float32) / 1000.0\n",
    "\n",
    "# Refine\n",
    "depth_refined = model(rgb, depth)\n",
    "```\n",
    "\n",
    "**Learn more:**\n",
    "- üìñ [GitHub Repository](https://github.com/Aedelon/camera-depth-models)\n",
    "- üì¶ [PyPI Package](https://pypi.org/project/rgbd-depth/)\n",
    "- üéÆ [HuggingFace Spaces Demo](https://huggingface.co/spaces/Aedelon/rgbd-depth)\n",
    "- üìÑ [Original Paper](https://manipulation-as-in-simulation.github.io/)\n",
    "\n",
    "---\n",
    "\n",
    "**Found this useful?** ‚≠ê Star the repo on GitHub!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "benchmark"
   },
   "source": [
    "## ‚ö° Performance Benchmark (Optional)\n",
    "\n",
    "Measure inference speed on this Colab instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "benchmark_code"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Warmup\n",
    "for _ in range(3):\n",
    "    _ = model(rgb, depth_raw)\n",
    "\n",
    "# Benchmark\n",
    "n_runs = 10\n",
    "times = []\n",
    "for _ in range(n_runs):\n",
    "    start = time.time()\n",
    "    _ = model(rgb, depth_raw)\n",
    "    torch.cuda.synchronize() if torch.cuda.is_available() else None\n",
    "    times.append(time.time() - start)\n",
    "\n",
    "mean_time = np.mean(times)\n",
    "std_time = np.std(times)\n",
    "fps = 1.0 / mean_time\n",
    "\n",
    "device_name = torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"CPU\"\n",
    "\n",
    "print(f\"\\n‚ö° Benchmark Results ({device_name}):\")\n",
    "print(f\"   Mean time: {mean_time*1000:.1f} ¬± {std_time*1000:.1f} ms\")\n",
    "print(f\"   Throughput: {fps:.2f} FPS\")\n",
    "print(f\"\\n   Reference (NVIDIA RTX 3090):\")\n",
    "print(f\"   - FP32: ~950ms (1.05 FPS)\")\n",
    "print(f\"   - FP16: ~520ms (1.92 FPS)\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
